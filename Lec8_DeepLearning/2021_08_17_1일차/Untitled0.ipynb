{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyNd2Ep+4Kdt/D2PdaUiZjE5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-8hHUAJR-sR","executionInfo":{"status":"ok","timestamp":1629173764224,"user_tz":-540,"elapsed":261,"user":{"displayName":"조현기","photoUrl":"","userId":"02064242295340458415"}},"outputId":"8f0d4e1b-3f90-4483-8a46-e7b4415f5c00"},"source":["import tensorflow as tf\n","\n","# 배달시간은 거리에 비례한다는 가정하에 간단하게 수식을 만들어 보자.\n","# 거리에 가중치를 곱하고 bias(편향, y좌표 위치)를 더한 식이다.\n","# 가중치의 변화는 그래프의 기울기 변화를 뜻하며 편향은 y좌표의 위치를 의미한다.\n","# 배달 시간 = 거리 * w + b\n","# 33분 = 850m * w + b\n","\n","label = 33\n","distance = 850\n","\n","# w와 b는 변수로 사용할 것이므로 tf.Variable로 지정\n","w = tf.Variable(0.)\n","b = tf.Variable(0.)\n","\n","# 변수만 출력할 경우 여러 정보들을 볼 수 있음.\n","print(w)\n","# 데이터값, 수치만 출력할 경우 numpy 함수를 이용할 수 있음.\n","print(w.numpy())\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>\n","0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FsyyvVXDSPTI","executionInfo":{"status":"ok","timestamp":1629174013868,"user_tz":-540,"elapsed":251,"user":{"displayName":"조현기","photoUrl":"","userId":"02064242295340458415"}}},"source":["# 손실함수는 예측값과 실제값의 차이를 줄여 알고리즘의 성능을 향상시킬때 사용하는 함수이다.\n","def loss_func():\n","  # 예측값을 얻기 위한 수식\n","  pred = distance * w + b\n","\n","  # 실제값과 예측값의 차액이 음수가 될 수 있음으로 square함수 처리\n","  return tf.square(label - pred)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"krXFaBKFVfoi","executionInfo":{"status":"ok","timestamp":1629174698289,"user_tz":-540,"elapsed":2079,"user":{"displayName":"조현기","photoUrl":"","userId":"02064242295340458415"}}},"source":["# 최적화 함수 중 평균적으로 성능이 좋은 Adam 함수 사용\n","# learning_rate는 0.1을 지정했으며, 0.01, 0.001 등을 사용할 수 있다.\n","opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n","\n","for i in range(1000):\n","  # 손실함수가 최소값을 갖기 위한 w, b 구하기\n","  opt.minimize(loss_func, var_list=[w, b])\n","  #print(w.numpy(), b.numpy())"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2a-KRE-ZWAVQ","executionInfo":{"status":"ok","timestamp":1629174698290,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현기","photoUrl":"","userId":"02064242295340458415"}},"outputId":"33f04200-43ea-46b5-d4ca-fff4d78f5fa9"},"source":["distance * w + b"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=32.999996>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"qW0W6fXgYTS6"},"source":["#Quiz \n","> 위의 코드를 이용하여, 손실함수가 최소값을 유지할 떄의 최소 반복횟수를 구하시오"]},{"cell_type":"code","metadata":{"id":"C8F7YifkYL1p"},"source":["opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n","\n","rec_w = -100\n","rec_b = -100\n","for i in range(1000):\n","  opt.minimize(loss_func, var_list=[w, b])\n","  print( rec_w, w.numpy(),  rec_b, b.numpy())\n","  if (rec_w == w.numpy()) and (rec_b == b.numpy()):\n","    break\n","  else:\n","    rec_w = w.numpy()\n","    rec_b = b.numpy()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUFCddD2Z1ZF","executionInfo":{"status":"ok","timestamp":1629175433120,"user_tz":-540,"elapsed":7,"user":{"displayName":"조현기","photoUrl":"","userId":"02064242295340458415"}},"outputId":"24e597b9-35fb-4eba-cb25-3c0b03f9e009"},"source":["print(i)\n","distance * w + b"],"execution_count":37,"outputs":[{"output_type":"stream","text":["303\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=32.999992>"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"_QHw23hLfYFA"},"source":["# Quiz 강사님코드"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFGqPqbmZ6L8","executionInfo":{"status":"ok","timestamp":1629176860953,"user_tz":-540,"elapsed":1472,"user":{"displayName":"조현기","photoUrl":"","userId":"02064242295340458415"}},"outputId":"208cc2bd-6d21-42f6-e266-883716d8b720"},"source":["opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n","\n","w_back = tf.Variable(0.)\n","b_back = tf.Variable(0.)\n","\n","cnt = tf.Variable(0.)\n","\n","while (True):\n","  opt.minimize(loss_func, var_list=[w, b])\n","  print(w.numpy(), b.numpy())\n","\n","  if (w.numpy() == w_back.numpy()) and (b.numpy() == b_back.numpy()):\n","    break\n"," \n","  # w_back = w\n","  # 참조가 같아져서 항상 같은 값을 나타내게 됨\n","\n","  w_back = tf.Variable(w.numpy())\n","  b_back = tf.Variable(b.numpy())\n","\n","  cnt.assign_add(1)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["-0.061179865 -0.059226524\n","0.013233561 0.015186902\n","0.084786355 0.08673972\n","0.114617825 0.11657119\n","0.10510945 0.10706282\n","0.07483876 0.07679212\n","0.03737142 0.03932478\n","0.004791308 0.0067446716\n","-0.013008431 -0.011055063\n","-0.013094324 -0.011140953\n","0.0011363355 0.0030897092\n","0.02378204 0.025735417\n","0.048156448 0.050109833\n","0.06761862 0.06957202\n","0.07729146 0.07924486\n","0.0757165 0.0776699\n","0.06468999 0.06664339\n","0.048018944 0.049972344\n","0.030456863 0.032410264\n","0.016707223 0.018660624\n","0.010157699 0.0121111\n","0.011886273 0.013839675\n","0.020624937 0.022578342\n","0.033432804 0.035386212\n","0.046549395 0.048502803\n","0.056349196 0.058302604\n","0.060363874 0.062317286\n","0.057969216 0.059922628\n","0.050394557 0.052347966\n","0.040199425 0.04215283\n","0.030501107 0.03245451\n","0.024083387 0.026036788\n","0.022572549 0.02452595\n","0.026006365 0.027959766\n","0.03295206 0.03490546\n","0.04103872 0.042992126\n","0.047707964 0.049661368\n","0.051007356 0.05296076\n","0.050180655 0.05213406\n","0.04582879 0.047782194\n","0.03962063 0.041574035\n","0.033699248 0.03565265\n","0.029968426 0.031921826\n","0.02947659 0.03142999\n","0.032119285 0.034072686\n","0.036754508 0.038707912\n","0.04165387 0.04360728\n","0.04512211 0.047075517\n","0.046079826 0.048033234\n","0.04440232 0.046355728\n","0.040898 0.042851407\n","0.036960054 0.038913462\n","0.034033887 0.035987295\n","0.033092596 0.035046004\n","0.034312535 0.036265943\n","0.03706351 0.03901692\n","0.04019726 0.042150673\n","0.0425095 0.04446291\n","0.04319712 0.045150533\n","0.042136516 0.04408993\n","0.03988309 0.0418365\n","0.037409373 0.039362784\n","0.035698395 0.037651803\n","0.035357304 0.037310712\n","0.036403585 0.038356993\n","0.038300518 0.04025393\n","0.040212248 0.04216566\n","0.041362874 0.04331629\n","0.04134846 0.043301877\n","0.040275928 0.042229343\n","0.03868131 0.040634725\n","0.0372752 0.039228614\n","0.03663201 0.038585424\n","0.036957297 0.038910713\n","0.038027782 0.039981198\n","0.03931904 0.041272454\n","0.040254045 0.04220746\n","0.04045757 0.042410985\n","0.03990493 0.041858345\n","0.038906228 0.040859643\n","0.037943605 0.03989702\n","0.037443403 0.03939682\n","0.03758927 0.039542686\n","0.038258 0.040211417\n","0.039099153 0.041052572\n","0.03971266 0.04166608\n","0.039836474 0.041789893\n","0.039456945 0.041410364\n","0.038795747 0.040749166\n","0.03818775 0.040141165\n","0.03791462 0.039868034\n","0.03807576 0.040029176\n","0.03855542 0.040508837\n","0.039095156 0.04104857\n","0.039429493 0.04138291\n","0.039414942 0.041368358\n","0.039090034 0.04104345\n","0.0386419 0.040595315\n","0.038302325 0.04025574\n","0.03822959 0.040183004\n","0.03843573 0.040389147\n","0.03879238 0.040745795\n","0.039106578 0.041059993\n","0.039223403 0.04117682\n","0.03910145 0.041054867\n","0.038824685 0.0407781\n","0.038549162 0.040502578\n","0.038416807 0.040370222\n","0.038483128 0.040436544\n","0.038695477 0.040648893\n","0.03892945 0.040882867\n","0.03906012 0.041013535\n","0.03902794 0.040981356\n","0.03886489 0.040818304\n","0.03866985 0.040623266\n","0.038550176 0.04050359\n","0.03856331 0.040516727\n","0.03868997 0.040643387\n","0.038850985 0.0408044\n","0.038955428 0.040908843\n","0.03895132 0.040904734\n","0.03885091 0.040804327\n","0.038718536 0.040671952\n","0.038630567 0.040583983\n","0.038631912 0.040585328\n","0.038713574 0.04066699\n","0.038822256 0.04077567\n","0.038894147 0.040847562\n","0.038891923 0.04084534\n","0.03882371 0.040777124\n","0.038734574 0.04068799\n","0.038677577 0.040630993\n","0.03868256 0.040635977\n","0.0387409 0.040694315\n","0.038813774 0.04076719\n","0.038857367 0.040810782\n","0.038848896 0.04080231\n","0.038798176 0.04075159\n","0.03873904 0.040692456\n","0.038707275 0.04066069\n","0.0387192 0.040672615\n","0.03876364 0.040717054\n","0.038810957 0.040764373\n","0.038832452 0.040785868\n","0.038817566 0.04077098\n","0.038778707 0.040732123\n","0.038741726 0.040695142\n","0.038728997 0.040682413\n","0.038746044 0.04069946\n","0.038779613 0.04073303\n","0.038807467 0.040760882\n","0.03881291 0.040766325\n","0.038794655 0.04074807\n","0.0387663 0.040719714\n","0.038746513 0.04069993\n","0.038746912 0.040700328\n","0.038765352 0.040718768\n","0.03878849 0.040741906\n","0.03880122 0.040754635\n","0.03879642 0.040749837\n","0.0387788 0.040732216\n","0.03876085 0.040714264\n","0.038754128 0.040707543\n","0.038761914 0.04071533\n","0.03877781 0.040731225\n","0.038790736 0.040744152\n","0.038792558 0.040745974\n","0.038783133 0.04073655\n","0.038769692 0.040723108\n","0.038761448 0.040714864\n","0.03876335 0.040716767\n","0.038773183 0.0407266\n","0.038783673 0.04073709\n","0.038787775 0.04074119\n","0.038783353 0.04073677\n","0.038774174 0.04072759\n","0.038766857 0.040720273\n","0.038766157 0.040719572\n","0.03877192 0.040725335\n","0.038779628 0.040733043\n","0.038783852 0.040737268\n","0.038782045 0.04073546\n","0.03877601 0.040729426\n","0.03877029 0.040723704\n","0.03876879 0.040722206\n","0.03877215 0.040725566\n","0.038777582 0.040730998\n","0.038781118 0.040734533\n","0.038780473 0.04073389\n","0.038776495 0.04072991\n","0.038772285 0.0407257\n","0.038770825 0.04072424\n","0.03877288 0.040726297\n","0.03877667 0.040730085\n","0.038779337 0.040732753\n","0.0387791 0.040732514\n","0.038776398 0.040729813\n","0.0387734 0.040726814\n","0.038772278 0.040725693\n","0.038773663 0.04072708\n","0.03877632 0.040729735\n","0.038778204 0.04073162\n","0.038778026 0.04073144\n","0.038776107 0.040729523\n","0.038774017 0.040727433\n","0.0387733 0.040726714\n","0.038774345 0.04072776\n","0.03877622 0.040729634\n","0.038777463 0.04073088\n","0.038777225 0.04073064\n","0.038775817 0.040729232\n","0.038774393 0.04072781\n","0.038774017 0.040727433\n","0.038774867 0.040728282\n","0.038776193 0.04072961\n","0.038776953 0.04073037\n","0.038776632 0.040730048\n","0.038775574 0.04072899\n","0.038774647 0.040728062\n","0.038774543 0.040727958\n","0.038775258 0.040728673\n","0.038776174 0.04072959\n","0.038776573 0.04072999\n","0.038776197 0.040729612\n","0.03877541 0.040728826\n","0.038774855 0.04072827\n","0.03877494 0.040728357\n","0.038775537 0.040728953\n","0.038776133 0.04072955\n","0.038776267 0.040729683\n","0.03877588 0.040729295\n","0.03877532 0.040728737\n","0.038775045 0.04072846\n","0.03877524 0.040728655\n","0.038775705 0.04072912\n","0.03877605 0.040729467\n","0.038776018 0.040729433\n","0.038775668 0.040729083\n","0.03877531 0.040728725\n","0.038775224 0.04072864\n","0.038775455 0.04072887\n","0.03877579 0.040729206\n","0.038775947 0.040729363\n","0.03877582 0.040729236\n","0.038775537 0.040728953\n","0.038775343 0.04072876\n","0.03877539 0.040728804\n","0.038775608 0.040729024\n","0.038775813 0.04072923\n","0.03877583 0.040729247\n","0.03877567 0.040729087\n","0.038775478 0.040728893\n","0.038775414 0.04072883\n","0.03877552 0.040728934\n","0.03877569 0.040729105\n","0.038775783 0.0407292\n","0.038775723 0.04072914\n","0.03877558 0.040728994\n","0.038775478 0.040728893\n","0.038775496 0.04072891\n","0.03877561 0.040729027\n","0.038775716 0.04072913\n","0.038775723 0.04072914\n","0.038775638 0.040729053\n","0.038775537 0.040728953\n","0.03877551 0.040728927\n","0.038775574 0.04072899\n","0.03877566 0.040729076\n","0.038775697 0.040729113\n","0.038775656 0.040729072\n","0.038775582 0.040728997\n","0.03877554 0.040728956\n","0.038775567 0.040728983\n","0.03877563 0.040729046\n","0.03877567 0.040729087\n","0.038775656 0.040729072\n","0.038775604 0.04072902\n","0.038775567 0.040728983\n","0.03877557 0.040728986\n","0.038775608 0.040729024\n","0.038775645 0.04072906\n","0.038775653 0.04072907\n","0.038775623 0.04072904\n","0.03877559 0.040729005\n","0.03877558 0.040728994\n","0.0387756 0.040729016\n","0.038775634 0.04072905\n","0.03877564 0.040729057\n","0.038775627 0.040729042\n","0.0387756 0.040729016\n","0.03877559 0.040729005\n","0.0387756 0.040729016\n","0.03877562 0.040729035\n","0.03877563 0.040729046\n","0.038775623 0.04072904\n","0.038775608 0.040729024\n","0.0387756 0.040729016\n","0.038775604 0.04072902\n","0.038775615 0.04072903\n","0.038775623 0.04072904\n","0.03877562 0.040729035\n","0.038775608 0.040729024\n","0.038775604 0.04072902\n","0.038775608 0.040729024\n","0.038775615 0.04072903\n","0.03877562 0.040729035\n","0.03877561 0.040729027\n","0.038775608 0.040729024\n","0.038775608 0.040729024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mtt4uNesgXAS","executionInfo":{"status":"ok","timestamp":1629176877653,"user_tz":-540,"elapsed":246,"user":{"displayName":"조현기","photoUrl":"","userId":"02064242295340458415"}},"outputId":"47dbed66-53fc-4c2a-a1f4-0a6303680843"},"source":["print(cnt.numpy())\n","distance * w + b"],"execution_count":42,"outputs":[{"output_type":"stream","text":["308.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=32.999996>"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"MGr6bi7fgjqE"},"source":[""],"execution_count":null,"outputs":[]}]}